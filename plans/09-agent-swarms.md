# Plan 09: Agent Swarms

*Depends on: Plan 04 (CRDT Operations), Plan 06 (Distribution), Plan 08 (AI Perspectives)*
*Enables: —*

## Goal

Scale kerai to support massive concurrent agent workloads — hundreds, thousands, or a million agents working on the same codebase simultaneously, converging toward test-passing solutions. This plan addresses the infrastructure, coordination patterns, observability, and economic participation needed to make swarm-scale development practical.

## The Development Model Shift

Traditional: a developer writes code, runs tests, iterates.

Swarm: you describe the problem, define the tests, unleash agents, and the codebase evolves *toward passing tests* as a convergent process. The database stores an evolving population of solutions. Agents read the current best state, propose mutations as CRDT operations on AST nodes, and the mutations that move tests from red to green are retained.

This is closer to evolutionary search than traditional development.

## Deliverables

### 9.1 Agent Lifecycle Management

```bash
# Register an agent
kerai agent register --name solver-1 --kind llm --model claude-opus-4-6

# Launch a swarm of agents against a task
kerai swarm launch \
  --task "make all tests in pkg/auth pass" \
  --agents 100 \
  --model claude-opus-4-6 \
  --timeout 1h \
  --budget 500000       # nKoi budget for the swarm

# Monitor running agents
kerai swarm status

# Stop a swarm
kerai swarm stop <swarm-id>
```

*Each agent registered via `kerai agent register` receives an Ed25519 keypair and a wallet (Plan 01). Under Plan 20, the agent's wallet operates in the shielded domain — the agent holds Koi as Pedersen commitments, and an embedded Fuchi-equivalent generates zK proofs for autonomous financial operations (auction bids, bounty claims, inter-agent transfers). The private key stays in the agent process, never on the server.*

### 9.2 Task Definition

A task is a node in the database (everything is a node) with:

- A description (natural language)
- A success criterion (test commands, assertions, or structural checks)
- A scope (which package/subtree agents should focus on)
- A budget (max operations, max time, max cost in nKoi)

```sql
CREATE TABLE tasks (
    id              uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    description     text NOT NULL,
    scope_node_id   uuid REFERENCES nodes(id),  -- subtree agents work on
    success_command text NOT NULL,                -- e.g., "cargo test --package auth"
    budget_ops      integer,                      -- max operations per agent
    budget_seconds  integer,                      -- max wall-clock time
    budget_nkoi     bigint,                       -- max nKoi spend (compute cost ceiling)
    funding_proof   bytea,                        -- zK proof that sponsor can cover budget (Plan 20, NULL in plaintext mode)
    sponsor_wallet  uuid REFERENCES wallets(id),  -- who funded the task
    status          text DEFAULT 'pending',       -- pending, running, succeeded, failed
    created_at      timestamptz DEFAULT now()
);
```

*The `budget_nkoi` field sets the economic ceiling for the task. In plaintext mode, the sponsor's balance is checked at settlement. Under Plan 20, `funding_proof` is a zK proof that the sponsor owns commitments worth >= `budget_nkoi`, without revealing total balance. This proof is generated by the sponsor's Fuchi client at task creation time.*

### 9.3 Branching via Version Vectors

Agents don't need git-style branches. A branch is just a version vector — a snapshot of state that an agent starts from:

```
-- Agent starts from current state
base_vector = {billy: 147, agent-1: 83}

-- Agent makes 50 operations
agent_vector = {billy: 147, agent-1: 83, solver-42: 50}

-- If tests pass, merge by broadcasting ops to the main database
-- If tests fail, discard — the ops were never pushed
```

No branch creation, no merge ceremony, no cleanup. An agent that fails simply doesn't share its operations. An agent that succeeds pushes its ops, and CRDT convergence handles the rest.

### 9.4 Test-Driven Convergence

The swarm coordination loop:

1. **Read:** Agent takes a snapshot of the current state (MVCC gives a consistent view)
2. **Mutate:** Agent modifies AST nodes within its scope
3. **Test:** Agent reconstructs source (Plan 03), runs the test command
4. **Evaluate:**
   - Tests pass → push operations to the shared database
   - Tests fail → discard operations (or push to a "failed attempts" log for learning)
5. **Repeat:** Agent reads the new state (which may include other agents' successful changes) and tries again

```sql
-- Record test results
CREATE TABLE test_results (
    id              uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    task_id         uuid NOT NULL REFERENCES tasks(id),
    agent_id        uuid NOT NULL REFERENCES agents(id),
    version_vector  jsonb NOT NULL,       -- state that was tested
    passed          boolean NOT NULL,
    output          text,                 -- test output for debugging
    duration_ms     integer,
    compute_cost    bigint DEFAULT 0,     -- nKoi: estimated compute cost of this attempt
    created_at      timestamptz DEFAULT now()
);

CREATE INDEX idx_test_results_task ON test_results(task_id);
CREATE INDEX idx_test_results_passed ON test_results(passed);
CREATE INDEX idx_test_results_agent ON test_results(agent_id);
```

*`compute_cost` tracks the nKoi value of each attempt — derived from the agent's model cost (API fees), test execution time, and any knowledge queries consumed. Under Plan 20, successful attempts auto-mint Koi proportional to their contribution (the agent that pushes a passing solution earns the reward). Failed attempts still cost compute but earn nothing — natural selection pressure toward efficiency.*

### 9.5 Agent Economics

Agents are autonomous economic actors. They earn Koi by producing value (passing tests, contributing knowledge) and spend Koi to acquire resources (knowledge from other instances, compute time, model inference).

**Earning:**
- Successful test convergence mints a reward (configurable in `reward_schedule`, work_type = `swarm_convergence`)
- Selling perspectives and associations via Dutch auctions (Plan 10)
- Claiming bounties posted by humans or other agents (Plan 11)

**Spending:**
- Acquiring knowledge from other instances (bid in auctions)
- Purchasing perspectives for unfamiliar code regions
- Compute cost for test execution and model inference
- Task budget contributions (agents can co-fund tasks they care about)

**Autonomous proof generation:**

An agent participating in the market needs to generate zK proofs without human intervention. Each agent process includes a lightweight Fuchi-equivalent — a Rust library that manages the agent's spending key, viewing key, and commitment inventory, and generates proofs on demand:

```rust
// Agent-side (not in the pgrx extension)
struct AgentWallet {
    spending_key: Ed25519PrivateKey,
    viewing_key:  ViewingKey,
    commitments:  Vec<Commitment>,  // tracked locally
}

impl AgentWallet {
    // Generate a funding proof for an auction bid
    fn prove_funding(&self, amount: u64) -> FundingProof { ... }

    // Generate a transfer proof (nullify inputs, create output commitments)
    fn prove_transfer(&self, to: &PublicKey, amount: u64) -> TransferProof { ... }

    // Scan the private ledger for incoming commitments
    fn scan_ledger(&self, ledger: &[Commitment]) -> Vec<OwnedCommitment> { ... }
}
```

*In plaintext mode (without Plan 20), agents use signed transfers with nonce-based replay protection (Plan 14). In private mode, the AgentWallet replaces nonce+signature with nullifier+proof. The agent's balance, earnings, and spending patterns are invisible to other agents and to the database.*

### 9.6 Swarm Market Dynamics

When agents operate at swarm scale with private wallets, emergent market behavior becomes possible:

**Knowledge arbitrage:** An agent that discovers a useful perspective in one code region can auction it to agents working in related regions. The seller proves (in zK) that the knowledge exists and has value; buyers bid based on their assessment of reproduction cost vs. purchase price.

**Cooperative task funding:** Multiple agents can co-fund a task they all benefit from. Each contributes nKoi with individual funding proofs. The task's `budget_nkoi` is the sum. If the task succeeds, the reward is distributed proportionally.

**Compute markets:** Agents with excess capacity can offer test execution services — "I'll run your test suite for X nKoi." The payment uses private transfers; the test result is a public attestation.

**Portfolio diversification:** An agent bidding on multiple concurrent auctions (Plan 10) generates separate funding proofs for each, each referencing distinct unspent commitments. If multiple auctions settle simultaneously, the nullifier mechanism prevents double-spending — one payment succeeds and the other requires the agent to provide alternative funding or forfeit.

### 9.7 Swarm Observability

Real-time dashboards and queries for monitoring swarm behavior:

```bash
# Which agents are producing passing changes?
kerai swarm leaderboard --task <task-id>

# What parts of the codebase are being modified most?
kerai swarm hotspots --since 1h

# Show the evolution of test pass rate over time
kerai swarm progress --task <task-id>

# Show an agent's operation history
kerai swarm trace --agent solver-42

# Economic overview of a swarm (public data only)
kerai swarm economics --task <task-id>
# Output:
#   Total budget: 500,000 nKoi
#   Spent: 312,000 nKoi (62.4%)
#   Agents: 100 (47 active, 53 idle)
#   Rewards minted: 85,000 nKoi (3 convergence events)
#   Knowledge acquired: 2 auction wins (45,000 nKoi)
```

Underlying queries:

```sql
-- Agent effectiveness
SELECT a.name,
    count(*) FILTER (WHERE tr.passed) as passes,
    count(*) FILTER (WHERE NOT tr.passed) as failures,
    round(100.0 * count(*) FILTER (WHERE tr.passed) / count(*), 1) as pass_rate
FROM test_results tr
JOIN agents a ON tr.agent_id = a.id
WHERE tr.task_id = '<task-id>'
GROUP BY a.name
ORDER BY pass_rate DESC;

-- Convergence rate: how fast are tests going green?
SELECT
    date_trunc('minute', created_at) as minute,
    count(*) FILTER (WHERE passed) as passes,
    count(*) FILTER (WHERE NOT passed) as failures
FROM test_results
WHERE task_id = '<task-id>'
GROUP BY minute
ORDER BY minute;

-- Compute cost efficiency: nKoi spent per successful pass
SELECT a.name,
    sum(tr.compute_cost) as total_cost,
    count(*) FILTER (WHERE tr.passed) as passes,
    CASE WHEN count(*) FILTER (WHERE tr.passed) > 0
         THEN sum(tr.compute_cost) / count(*) FILTER (WHERE tr.passed)
         ELSE NULL END as cost_per_pass
FROM test_results tr
JOIN agents a ON tr.agent_id = a.id
WHERE tr.task_id = '<task-id>'
GROUP BY a.name
ORDER BY cost_per_pass NULLS LAST;

-- Lineage of a function from failing to passing
SELECT o.*, tr.passed
FROM operations o
JOIN nodes n ON o.node_id = n.id
LEFT JOIN test_results tr ON tr.version_vector @> jsonb_build_object(o.author, o.author_seq)
WHERE n.path <@ 'crate.auth.validate_token'
ORDER BY o.lamport_ts;
```

*Economic queries like `swarm economics` are derived from public data: task budgets (selectively disclosed at creation), reward mints (public amounts tied to work proofs), and auction settlements (public prices). Individual agent balances, transfer histories, and spending patterns remain private under Plan 20.*

### 9.8 Postgres Scaling for Swarm Workloads

At swarm scale, the database sees:
- High write throughput on `operations` (many agents committing concurrently)
- High read throughput on `nodes` (agents reading current state)
- Moderate write throughput on `test_results`

Postgres tuning for this workload:

```sql
-- Partition operations by author for write throughput
CREATE TABLE operations (
    ...
) PARTITION BY HASH (author);

-- Create partitions (one per expected concurrent agent group)
CREATE TABLE operations_p0 PARTITION OF operations FOR VALUES WITH (MODULUS 16, REMAINDER 0);
CREATE TABLE operations_p1 PARTITION OF operations FOR VALUES WITH (MODULUS 16, REMAINDER 1);
-- ... through p15

-- Unlogged tables for test_results (ephemeral, can be regenerated)
-- Faster writes at the cost of crash recovery
CREATE UNLOGGED TABLE test_results (...);
```

Connection pooling via PgBouncer or Postgres's built-in connection limits:
- 1,000 agents with connection pooling: ~50-100 actual Postgres connections
- 1,000,000 agents: tiered architecture with agent groups sharing connections

### 9.9 Version Vector Compression

At swarm scale, version vectors with one entry per agent become unwieldy. Solution: hierarchical grouping.

```
-- Instead of a million entries:
{solver-1: 50, solver-2: 48, solver-3: 52, ...}

-- Group by swarm job:
{billy: 147, swarm-job-58a3: 12041}

-- Where swarm-job-58a3's internal state is tracked separately
-- The shared database only sees the aggregate
```

An agent swarm shares a single identity in the version vector. Internally, the swarm tracks per-agent state. When ops are pushed to the shared database, they're attributed to the swarm job, not individual agents.

*Financial operations are NOT grouped — each agent's wallet is individual, even when the agent's code contributions are attributed to the swarm. This separation is deliberate: an agent's economic identity persists across swarm jobs. An agent that earned Koi in swarm-job-1 keeps that balance for swarm-job-2.*

## Decisions to Make

- **Agent orchestration:** Should kerai itself orchestrate agents (launching LLM API calls), or should it be a passive database that external orchestrators write to? Proposed: start passive — agents are external processes that connect via the standard CLI/SQL. Add built-in orchestration later.
- **Failed attempt retention:** Should failed mutations be stored for analysis? Proposed: store in a separate `failed_operations` table for post-mortem analysis, with automatic TTL-based cleanup.
- **Resource limits:** How to prevent a swarm from overwhelming the database? Proposed: per-task rate limits (max ops/sec), per-agent budgets (max ops per attempt), and circuit breakers that pause the swarm if Postgres load exceeds thresholds.
- **Multi-machine swarms:** A million agents won't run on one machine. The connection string model already supports pointing agents at a remote Postgres. But should kerai also help launch agents across multiple machines? Proposed: out of scope — use existing orchestration tools (Kubernetes, Docker Swarm, etc.) to distribute agents. Kerai just needs to handle the database side.
- **Agent wallet provisioning:** Should swarm launch auto-create wallets for each agent, or should agents bring their own? Proposed: auto-create at registration. The orchestrator that launches the swarm holds the spending keys and distributes them to agent processes. Under Plan 20, each agent generates its own keypair — the orchestrator never sees spending keys, only public keys.
- **Swarm-level funding:** Should a swarm have a shared treasury, or does each agent fund itself? Proposed: sponsor funds the task via `budget_nkoi` + `funding_proof`. The task budget is a ceiling, not a pre-allocation. Individual agents earn and spend from their own wallets. The sponsor pays only for the final reward, not for intermediate compute.

## Out of Scope

- Agent intelligence / prompting strategies (how to make agents write good code)
- Cost management for external LLM providers (tracking API spend across providers — agents manage their own external costs and convert to nKoi internally)
- Agent communication beyond the shared database (agents don't talk to each other — they communicate through the codebase and the market)
